{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "P8BhSX1n27Hv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqq ipdb\n",
        "import ipdb"
      ],
      "metadata": {
        "id": "NpS9j670ARpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91c3f19f-e2d5-4232-db46-45f1c1c288f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 792 kB 35.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 375 kB 47.4 MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.26 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.31.1 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os; os.environ['KERAS_BACKEND'] = 'theano'"
      ],
      "metadata": {
        "id": "LfPzFXC3xZcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fff298-8ee0-4cb3-a705-dba0791b0eb3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[autoreload of IPython.core.debugger failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    del self.failed[py_filename]\n",
            "ValueError: wrapper() requires a code object with 1 free vars, not 0\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "alv5Cnmvtdhp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "sys.path.append('drive/MyDrive/PBP_net')\n",
        "from PBP_net import PBP_net\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "# We load the boston housing dataset\n",
        "data = np.loadtxt('drive/MyDrive/PBP_net/boston_housing.txt')\n",
        "# We obtain the features and the targets\n",
        "X = data[:, range(data.shape[1] - 1)]\n",
        "y = data[:, data.shape[1] - 1]"
      ],
      "metadata": {
        "id": "hP3io6pevDC4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491de5c5-c25b-4f65-b90c-c9dbdaa4d9db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method AutoreloadMagics.post_execute_hook of <autoreload.AutoreloadMagics object at 0x7f5ce3ea3750>> (for post_execute):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We create the train and test sets with 90% and 10% of the data\n",
        "permutation = np.random.choice(range(X.shape[0]), X.shape[0], replace = False)\n",
        "size_train = np.round(X.shape[0] * 0.9).astype(int)\n",
        "index_train = permutation[0:size_train]\n",
        "index_test = permutation[size_train:]"
      ],
      "metadata": {
        "id": "jOE3BnMVvfbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4138275b-c8f5-44fd-8fd5-2fd3d74e8411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method AutoreloadMagics.post_execute_hook of <autoreload.AutoreloadMagics object at 0x7f5ce3ea3750>> (for post_execute):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X[index_train, : ]\n",
        "y_train = y[index_train]\n",
        "X_test = X[index_test,:]\n",
        "y_test = y[index_test]"
      ],
      "metadata": {
        "id": "IhTuniJ_v0Md",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56886270-f3c9-48f0-df6e-73585578a0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in callback <bound method AutoreloadMagics.post_execute_hook of <autoreload.AutoreloadMagics object at 0x7f5ce3ea3750>> (for post_execute):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We construct the network with one hidden layer with two-hidden layers\n",
        "# with 50 neurons in each one and normalizing the training features to have\n",
        "# zero mean and unit standard deviation in the trainig set.\n",
        "n_hidden_units = 50\n",
        "net = PBP_net(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    [n_hidden_units, n_hidden_units],\n",
        "    normalize=True,\n",
        "    n_epochs=40\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uMM_lnVwM-a",
        "outputId": "0f181566-5d73-4a60-e0a7-380c81c88c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(455, 13)\n",
            "1.2961548806173255e-15 X_train mean\n",
            "1.0000000000000002 X_train std\n",
            "(455,)\n",
            "22.77846153846154\n",
            "9.32785370682845\n",
            "[13 50 50  1]\n",
            "0 14 0\n",
            "1 51 1\n",
            "2 51 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We make predictions for the test set\n",
        "m, v, v_noise = net.predict(X_test)\n",
        "# We compute the test RMSE\n",
        "rmse = np.sqrt(np.mean((y_test - m)**2))\n",
        "print(rmse)\n",
        "\n",
        "# We compute the test log-likelihood\n",
        "test_ll = np.mean(-0.5 * np.log(2 * math.pi * (v + v_noise)) - \\\n",
        "    0.5 * (y_test - m)**2 / (v + v_noise))\n",
        "print(test_ll)"
      ],
      "metadata": {
        "id": "OmWOGUQYwXJe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}